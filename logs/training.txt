2021-06-25 17:16:18,608: <INFO> Trying efficent model
2021-06-25 17:16:18,730: <INFO> Training model: attempt 0
2021-06-25 17:16:18,909: <INFO> Model: "efficient"
2021-06-25 17:16:18,909: <INFO> _________________________________________________________________
2021-06-25 17:16:18,910: <INFO> Layer (type)                 Output Shape              Param #   
2021-06-25 17:16:18,911: <INFO> =================================================================
2021-06-25 17:16:18,913: <INFO> dense1 (Dense)               (None, 7, 7, 128)         163968    
2021-06-25 17:16:18,914: <INFO> _________________________________________________________________
2021-06-25 17:16:18,914: <INFO> activation1 (Activation)     (None, 7, 7, 128)         0         
2021-06-25 17:16:18,915: <INFO> _________________________________________________________________
2021-06-25 17:16:18,916: <INFO> dense2 (Dense)               (None, 7, 7, 4)           516       
2021-06-25 17:16:18,917: <INFO> _________________________________________________________________
2021-06-25 17:16:18,917: <INFO> activation2 (Activation)     (None, 7, 7, 4)           0         
2021-06-25 17:16:18,918: <INFO> _________________________________________________________________
2021-06-25 17:16:18,919: <INFO> dense3 (Dense)               (None, 7, 7, 1)           5         
2021-06-25 17:16:18,919: <INFO> _________________________________________________________________
2021-06-25 17:16:18,920: <INFO> activation3 (Activation)     (None, 7, 7, 1)           0         
2021-06-25 17:16:18,920: <INFO> _________________________________________________________________
2021-06-25 17:16:18,921: <INFO> pool (GlobalMaxPooling2D)    (None, 1)                 0         
2021-06-25 17:16:18,921: <INFO> =================================================================
2021-06-25 17:16:18,923: <INFO> Total params: 164,489
2021-06-25 17:16:18,924: <INFO> Trainable params: 164,489
2021-06-25 17:16:18,924: <INFO> Non-trainable params: 0
2021-06-25 17:16:18,925: <INFO> _________________________________________________________________
2021-06-25 21:47:51,972: <INFO> Epoch 0, loss 0.4741
2021-06-25 21:47:51,981: <INFO> Epoch 1, loss 0.4120
2021-06-25 21:47:51,981: <INFO> Epoch 2, loss 0.3849
2021-06-25 21:47:51,981: <INFO> Epoch 3, loss 0.3629
2021-06-25 21:47:51,982: <INFO> Epoch 4, loss 0.3436
2021-06-25 21:47:51,982: <INFO> Epoch 5, loss 0.3266
2021-06-25 21:47:51,982: <INFO> Epoch 6, loss 0.3114
2021-06-25 21:47:51,983: <INFO> Epoch 7, loss 0.2977
2021-06-25 21:47:51,983: <INFO> Epoch 8, loss 0.2843
2021-06-25 21:47:51,983: <INFO> Epoch 9, loss 0.2723
2021-06-25 21:47:51,984: <INFO> Epoch 10, loss 0.2629
2021-06-25 21:47:51,984: <INFO> Epoch 11, loss 0.2514
2021-06-25 21:47:51,984: <INFO> Epoch 12, loss 0.2440
2021-06-25 21:47:51,984: <INFO> Epoch 13, loss 0.2350
2021-06-25 21:47:51,985: <INFO> Epoch 14, loss 0.2281
2021-06-25 21:47:51,985: <INFO> Epoch 15, loss 0.2224
2021-06-25 21:47:51,985: <INFO> Epoch 16, loss 0.2146
2021-06-25 21:47:51,985: <INFO> Epoch 17, loss 0.2118
2021-06-25 21:47:51,986: <INFO> Epoch 18, loss 0.2064
2021-06-25 21:47:51,986: <INFO> Epoch 19, loss 0.2024
2021-06-25 21:47:51,986: <INFO> Epoch 20, loss 0.1985
2021-06-25 21:47:51,986: <INFO> Epoch 21, loss 0.1955
2021-06-25 21:47:51,987: <INFO> Epoch 22, loss 0.1899
2021-06-25 21:47:51,987: <INFO> Epoch 23, loss 0.1869
2021-06-25 21:47:51,987: <INFO> Epoch 24, loss 0.1832
2021-06-25 21:47:51,988: <INFO> Epoch 25, loss 0.1801
2021-06-25 21:47:51,989: <INFO> Epoch 26, loss 0.1781
2021-06-25 21:47:51,989: <INFO> Epoch 27, loss 0.1755
2021-06-25 21:47:51,989: <INFO> Epoch 28, loss 0.1721
2021-06-25 21:47:51,990: <INFO> Epoch 29, loss 0.1700
2021-06-25 21:47:51,990: <INFO> Epoch 30, loss 0.1654
2021-06-25 21:47:51,991: <INFO> Epoch 31, loss 0.1630
2021-06-25 21:47:51,991: <INFO> Epoch 32, loss 0.1639
2021-06-25 21:47:51,991: <INFO> Epoch 33, loss 0.1618
2021-06-25 21:47:51,992: <INFO> Epoch 34, loss 0.1578
2021-06-25 21:47:51,992: <INFO> Epoch 35, loss 0.1573
2021-06-25 21:47:51,993: <INFO> Epoch 36, loss 0.1535
2021-06-25 21:47:51,993: <INFO> Epoch 37, loss 0.1520
2021-06-25 21:47:51,994: <INFO> Epoch 38, loss 0.1538
2021-06-25 21:47:51,995: <INFO> Epoch 39, loss 0.1506
2021-06-25 21:47:51,995: <INFO> Epoch 40, loss 0.1495
2021-06-25 21:47:51,997: <INFO> Epoch 41, loss 0.1460
2021-06-25 21:47:51,997: <INFO> Epoch 42, loss 0.1461
2021-06-25 21:47:51,998: <INFO> Epoch 43, loss 0.1445
2021-06-25 21:47:51,998: <INFO> Epoch 44, loss 0.1436
2021-06-25 21:47:51,999: <INFO> Epoch 45, loss 0.1416
2021-06-25 21:47:51,999: <INFO> Epoch 46, loss 0.1423
2021-06-25 21:47:52,000: <INFO> Epoch 47, loss 0.1416
2021-06-25 21:47:52,000: <INFO> Epoch 48, loss 0.1384
2021-06-25 21:47:52,000: <INFO> Epoch 49, loss 0.1404
2021-06-25 21:47:52,001: <INFO> Epoch 50, loss 0.1370
2021-06-25 21:47:52,001: <INFO> Epoch 51, loss 0.1372
2021-06-25 21:47:52,002: <INFO> Epoch 52, loss 0.1360
2021-06-25 21:47:52,002: <INFO> Epoch 53, loss 0.1355
2021-06-25 21:47:52,003: <INFO> Epoch 54, loss 0.1341
2021-06-25 21:47:52,012: <INFO> Epoch 55, loss 0.1339
2021-06-25 21:47:52,014: <INFO> Epoch 56, loss 0.1336
2021-06-25 21:47:52,014: <INFO> Epoch 57, loss 0.1323
2021-06-25 21:47:52,016: <INFO> Epoch 58, loss 0.1308
2021-06-25 21:47:52,016: <INFO> Epoch 59, loss 0.1305
2021-06-25 21:47:52,018: <INFO> Epoch 60, loss 0.1292
2021-06-25 21:47:52,019: <INFO> Epoch 61, loss 0.1306
2021-06-25 21:47:52,026: <INFO> Epoch 62, loss 0.1291
2021-06-25 21:47:52,026: <INFO> Epoch 63, loss 0.1270
2021-06-25 21:47:52,027: <INFO> Epoch 64, loss 0.1277
2021-06-25 21:47:52,028: <INFO> Epoch 65, loss 0.1273
2021-06-25 21:47:52,029: <INFO> Epoch 66, loss 0.1259
2021-06-25 21:47:52,030: <INFO> Epoch 67, loss 0.1260
2021-06-25 21:47:52,030: <INFO> Epoch 68, loss 0.1269
2021-06-25 21:47:56,376: <INFO> Assets written to: trained_models/efficent\assets
2021-06-25 21:47:56,577: <INFO> Best loss is 0.126855
2021-06-25 21:51:07,374: <INFO> Training accuracy is 93.4%
2021-06-25 22:35:08,922: <INFO> Trying efficent model
2021-06-25 22:37:28,612: <INFO> Testing accuracy is 80.3%
